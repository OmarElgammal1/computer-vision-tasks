{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa82d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31096047",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"data_path\": \"/kaggle/input/teeth-disease-classification/Teeth_Dataset\",\n",
    "    \"num_classes\": 7,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 15,\n",
    "    \"learning_rate\": 0.001,\n",
    "    # Pre-trained models expect 224x224 images\n",
    "    \"image_size\": (224, 224),\n",
    "    \"class_names\": [\"CaS\", \"CoS\", \"Gum\", \"MC\", \"OC\", \"OLP\", \"OT\"],\n",
    "    \"model_save_path\": \"dental_classifier_model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed97172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transforms(image_size):\n",
    "    # Standard transforms for ImageNet-trained models\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f661f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DentalDataset(Dataset):\n",
    "    def __init__(self, data_dir, class_map, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.class_map = class_map\n",
    "        self.image_paths, self.labels = self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            raise FileNotFoundError(f\"Data directory not found: {self.data_dir}\")\n",
    "        for class_name, label_idx in self.class_map.items():\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    labels.append(label_idx)\n",
    "        return image_paths, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e73619",
   "metadata": {},
   "source": [
    "## Model Architecture (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a32109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes, pretrained=True):\n",
    "    # Load a pre-trained ResNet-50 model\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "\n",
    "    # Freeze all the parameters in the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    # Replace the final fully connected layer with a new one for our specific task\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727eab6",
   "metadata": {},
   "source": [
    "## Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae1e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    print(\"\\n--- Starting Model Training (Transfer Learning) ---\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        val_accuracy = evaluate_model(model, val_loader, device, None)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(\"--- Finished Training ---\")\n",
    "\n",
    "def evaluate_model(model, data_loader, device, set_name=\"Test\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    if set_name:\n",
    "        print(f\"Accuracy on the {set_name} set: {accuracy:.2f} %\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99747a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded 3087 images for training.\n",
      "Loaded 1028 images for validation.\n",
      "Loaded 1028 images for testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training (Transfer Learning) ---\n",
      "Epoch [1/15], Loss: 1.5233, Val Accuracy: 63.81%\n",
      "Epoch [2/15], Loss: 1.1295, Val Accuracy: 64.59%\n",
      "Epoch [3/15], Loss: 0.9966, Val Accuracy: 62.84%\n",
      "Epoch [4/15], Loss: 0.9408, Val Accuracy: 69.26%\n",
      "Epoch [5/15], Loss: 0.8641, Val Accuracy: 71.79%\n",
      "Epoch [6/15], Loss: 0.8303, Val Accuracy: 66.15%\n",
      "Epoch [7/15], Loss: 0.8304, Val Accuracy: 67.32%\n",
      "Epoch [8/15], Loss: 0.7863, Val Accuracy: 75.00%\n",
      "Epoch [9/15], Loss: 0.7454, Val Accuracy: 75.39%\n",
      "Epoch [10/15], Loss: 0.7527, Val Accuracy: 71.40%\n",
      "Epoch [11/15], Loss: 0.7129, Val Accuracy: 75.19%\n",
      "Epoch [12/15], Loss: 0.7013, Val Accuracy: 76.85%\n",
      "Epoch [13/15], Loss: 0.6775, Val Accuracy: 75.58%\n",
      "Epoch [14/15], Loss: 0.6949, Val Accuracy: 75.19%\n",
      "Epoch [15/15], Loss: 0.6748, Val Accuracy: 75.39%\n",
      "--- Finished Training ---\n",
      "\n",
      "--- Final Evaluation ---\n",
      "Accuracy on the Test set: 76.85 %\n",
      "\n",
      "Saving model to dental_classifier_model.pth...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_dir = os.path.join(CONFIG[\"data_path\"], \"Training\")\n",
    "val_dir = os.path.join(CONFIG[\"data_path\"], \"Validation\")\n",
    "test_dir = os.path.join(CONFIG[\"data_path\"], \"Testing\")\n",
    "train_transform, val_transform = get_transforms(CONFIG[\"image_size\"])\n",
    "\n",
    "class_map = {name: i for i, name in enumerate(CONFIG[\"class_names\"])}\n",
    "\n",
    "try:\n",
    "    train_dataset = DentalDataset(train_dir, class_map, train_transform)\n",
    "    val_dataset = DentalDataset(val_dir, class_map, val_transform)\n",
    "    test_dataset = DentalDataset(test_dir, class_map, val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    print(f\"Loaded {len(train_dataset)} images for training.\")\n",
    "    print(f\"Loaded {len(val_dataset)} images for validation.\")\n",
    "    print(f\"Loaded {len(test_dataset)} images for testing.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "model = get_model(CONFIG[\"num_classes\"]).to(device)\n",
    "\n",
    "# We only want to train the parameters of the final layer\n",
    "params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(params_to_update, lr=CONFIG[\"learning_rate\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, CONFIG[\"num_epochs\"], device)\n",
    "\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "evaluate_model(model, test_loader, device, \"Test\")\n",
    "\n",
    "print(f\"\\nSaving model to {CONFIG['model_save_path']}...\")\n",
    "torch.save(model.state_dict(), CONFIG['model_save_path'])\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
